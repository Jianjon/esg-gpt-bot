from openai import OpenAI
from dotenv import load_dotenv
import os
from typing import List, Dict
from src.utils.message_builder import build_chat_messages
from src.utils.rag_retriever import RAGRetriever  # âœ… æ–°å¢ï¼šRAG å‘é‡è£œå……æ¨¡çµ„
import inspect
import streamlit as st  # âœ… è‹¥ç”¨åœ¨ Streamlit ç•«é¢ä¸­é™¤éŒ¯æç¤º

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

def call_gpt(
    prompt: str,
    question_text: str = "",
    learning_goal: str = "",
    chat_history: List[Dict[str, str]] = None,
    industry: str = "",
    rag_doc: str = None,  # âœ… æ–°å¢ï¼šæŒ‡å®šå‘é‡æ–‡ä»¶ï¼ˆè³‡æ–™å¤¾ï¼‰åç¨±
    model: str = "gpt-3.5-turbo-1106",
    temperature: float = 0.4
) -> str:
    """
    å‘¼å« GPT æ¨¡å‹ï¼Œæ•´åˆå•é¡Œè„ˆçµ¡èˆ‡æ­·å²è¨˜æ†¶çµ¦å‡ºå›ç­”
    å¯é¸ç”¨ RAG æ¨¡å¼è£œå……æ®µè½èƒŒæ™¯
    """
    try:
        rag_context = ""
        if rag_doc:
            retriever = RAGRetriever()
            rag_context = retriever.get_context(prompt, doc_folder=rag_doc)

        # æª¢æŸ¥ prompt èˆ‡ä¸Šä¸‹æ–‡è¨Šæ¯
        messages = build_chat_messages(
            prompt=prompt,
            question_text=question_text,
            learning_goal=learning_goal,
            chat_history=chat_history,
            industry=industry
        )

        # å¦‚æœæœ‰ RAG æ®µè½è£œå……ï¼Œæ’å…¥åœ¨ç¬¬ä¸€å‰‡ system message å¾Œ
        if rag_context and len(messages) > 0:
            rag_block = f"ä»¥ä¸‹æ˜¯è¼”åŠ©åƒè€ƒæ®µè½ï¼ˆä¾†è‡ªæ–‡ç»ï¼‰ï¼š\n{rag_context}"
            if messages[0]["role"] == "system":
                messages[0]["content"] += f"\n\n{rag_block}"
            else:
                messages.insert(0, {"role": "system", "content": rag_block})

        print("ğŸ§ª [call_gpt] å¯¦éš›é€å‡ºçš„ messagesï¼š")
        for msg in messages:
            print(f"{msg['role']}: {msg['content'][:100]}...")

        # å‘¼å« OpenAI API
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=700
        )

        content = response.choices[0].message.content.strip()

        if not content:
            print("âš ï¸ GPT å›å‚³ç‚ºç©º")
        return content

    except Exception as e:
        print(f"âš ï¸ GPT å›æ‡‰éŒ¯èª¤ï¼š{e}")
        st.warning(f"âš ï¸ ç„¡æ³•å–å¾— AI å›è¦†ï¼Œè«‹ç¨å¾Œå†è©¦ï¼š{e}")
        return "ç›®å‰ç„¡æ³•å–å¾— AI å›è¦†ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

# âœ… Debug logï¼Œç¢ºèªä¾†æºæª”æ¡ˆèˆ‡æ˜¯å¦è¼‰å…¥
print("âœ… call_gpt è¢«è¼‰å…¥äº†ï¼ä¾†æºï¼š", inspect.getfile(call_gpt))