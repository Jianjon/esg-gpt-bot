# src/utils/gpt_tools.py

from openai import OpenAI
from dotenv import load_dotenv
import os
from typing import List, Dict
from src.utils.message_builder import build_chat_messages
import inspect
import streamlit as st

# âœ… å¯é¸ç”¨ï¼šå•Ÿç”¨ RAG æ®µè½è£œå……
USE_RAG = os.getenv("USE_RAG", "false").lower() == "true"
if USE_RAG:
    try:
        from src.utils.rag_retriever import RAGRetriever
    except ImportError:
        print("âš ï¸ å•Ÿç”¨ USE_RAG ä½†æ‰¾ä¸åˆ° rag_retrieverï¼Œè‡ªå‹•é—œé–‰ RAG åŠŸèƒ½")
        USE_RAG = False

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key, timeout=20)  # âœ… å»ºè­°åŠ ä¸Š timeout ä¿è­·

def call_gpt(
    prompt: str,
    question_text: str = "",
    learning_goal: str = "",
    chat_history: List[Dict[str, str]] = None,
    industry: str = "",
    rag_doc: str = None,
    model: str = "gpt-3.5-turbo-1106",
    temperature: float = 0.4
) -> str:
    """
    å‘¼å« GPT æ¨¡å‹ï¼Œæ•´åˆå•é¡Œè„ˆçµ¡èˆ‡æ­·å²è¨˜æ†¶çµ¦å‡ºå›ç­”
    å¯é¸ç”¨ RAG æ¨¡å¼è£œå……æ®µè½èƒŒæ™¯ï¼ˆéœ€ç’°å¢ƒè®Šæ•¸ USE_RAG=trueï¼‰
    """
    try:
        rag_context = ""
        if USE_RAG and rag_doc:
            retriever = RAGRetriever()
            rag_context = retriever.get_context(prompt, doc_folder=rag_doc)

        # çµ„åˆ messages
        messages = build_chat_messages(
            prompt=prompt,
            question_text=question_text,
            learning_goal=learning_goal,
            chat_history=chat_history,
            industry=industry
        )

        # æ’å…¥ RAG æ®µè½ï¼ˆè‹¥æœ‰ï¼‰
        if rag_context and messages:
            rag_block = f"ä»¥ä¸‹æ˜¯è¼”åŠ©åƒè€ƒæ®µè½ï¼ˆä¾†è‡ªæ–‡ç»ï¼‰ï¼š\n{rag_context}"
            if messages[0]["role"] == "system":
                messages[0]["content"] += f"\n\n{rag_block}"
            else:
                messages.insert(0, {"role": "system", "content": rag_block})

        # âœ… å°å‡ºå¯¦éš›é€å‡ºçš„å…§å®¹ï¼ˆæœ€å¤šå‰ 100 å­—ï¼‰
        print("ğŸ§ª [call_gpt] å¯¦éš›é€å‡ºçš„ messagesï¼š")
        for msg in messages:
            print(f"{msg['role']}: {msg['content'][:100]}...")

        # å‘¼å« OpenAI GPT
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=700
        )

        content = response.choices[0].message.content.strip()
        if not content:
            print("âš ï¸ GPT å›å‚³ç‚ºç©º")
            return "âš ï¸ AI å›è¦†ç‚ºç©ºï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

        return content

    except Exception as e:
        print(f"âš ï¸ GPT å›æ‡‰éŒ¯èª¤ï¼š{e}")
        st.warning(f"âš ï¸ ç„¡æ³•å–å¾— AI å›è¦†ï¼Œè«‹ç¨å¾Œå†è©¦ï¼š{e}")
        return f"âš ï¸ ç„¡æ³•å–å¾— AI å›è¦†ï¼Œè«‹ç¨å¾Œå†è©¦ï¼š{e}"

# âœ… ç¢ºèªä¾†æºèˆ‡æ˜¯å¦æ­£ç¢ºè¼‰å…¥
print("âœ… call_gpt è¢«è¼‰å…¥äº†ï¼ä¾†æºï¼š", inspect.getfile(call_gpt))
