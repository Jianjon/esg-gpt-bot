# src/components/sidebar_fragment.py

import streamlit as st
from collections import defaultdict
from typing import List, Dict
from src.utils.report_utils import generate_full_gpt_report
from src.managers.profile_manager import get_user_profile

user_profile = get_user_profile()

@st.fragment
def render_sidebar_fragment(session, current_q):
    st.title("ğŸ“‹ ESG Service Path")
    st.markdown("---")
    st.header("ğŸ‘¤ ä½¿ç”¨è€…è³‡è¨Š")
    st.markdown(f"**å§“åï¼š** {st.session_state.get('user_name', 'æœªç™»å…¥')}")
    st.markdown(f"**éšæ®µï¼š** {'åˆéš' if st.session_state.get('stage') == 'basic' else 'é€²éš'}")

    # âœ… é€²åº¦é¡¯ç¤ºæ”¹ç‚ºã€Œå·²ä½œç­”é¡Œæ•¸ã€
    answered_ids = {r["question_id"] for r in session.responses}
    total_questions = len(session.question_set)
    answered = len(answered_ids)
    st.markdown(f"**ç›®å‰é€²åº¦ï¼š** {answered} / {total_questions} é¡Œ")

    st.markdown("---")
    st.markdown("### ğŸ“Š ä¸»é¡Œé€²åº¦æ¦‚è¦½")

    current_topic = current_q.get("topic", "")
    topic_groups = defaultdict(list)
    for q in session.question_set:
        topic_groups[q["topic"]].append(q)

    for topic, q_list in topic_groups.items():
        total = len(q_list)
        topic_answered = sum(1 for q in q_list if q["id"] in answered_ids)
        checked = "âœ… " if topic_answered == total else ""
        expanded = topic == current_topic

        with st.expander(f"{checked}{topic}", expanded=expanded):
            for i, q in enumerate(q_list):
                qid = q["id"]
                is_answered = qid in answered_ids
                label_key = f"label_{qid}"
                label = st.session_state.get(label_key, q["text"][:12].strip())
                display_label = f"{'âœ”ï¸ ' if is_answered else ''}{i+1}. {label}"

                if st.button(display_label, key=f"jump_to_{qid}"):
                    st.session_state["jump_to"] = qid
                    st.session_state["_trigger_all_sections"] = st.session_state.get("_trigger_all_sections", 0) + 1

    # === å ±å‘Šå€å¡Š ===
    st.markdown("---")
    st.subheader("ğŸ§¾ æ¸¬é©—è¨ºæ–·å ±å‘Š")
    st.caption(f"Debugï¼šå·²å›ç­” {answered} é¡Œ / å…± {total_questions} é¡Œ")

    REQUIRED_QUESTIONS = 10
    if answered < REQUIRED_QUESTIONS:
        st.info(f"âš ï¸ è«‹å…ˆå®Œæˆè‡³å°‘ {REQUIRED_QUESTIONS} é¡Œï¼Œæ‰èƒ½æŸ¥çœ‹è¨ºæ–·å ±å‘Šã€‚\n\nğŸ’¡ å»ºè­°å®Œæ•´åƒèˆ‡ AI é¡§å•æ•™å­¸äº’å‹•ï¼Œè®“å ±å‘Šæ›´è²¼è¿‘æ‚¨çš„æƒ…å¢ƒèˆ‡éœ€æ±‚ã€‚")
    else:
        if st.button("ğŸ“„ ç”¢å‡ºç›®å‰å ±å‘Šï¼ˆGPT-4ï¼‰"):
            with st.spinner("AI é¡§å•åˆ†æä¸­..."):
                try:
                    context_history = st.session_state.get("context_history", [])
                    tone = st.session_state.get("preferred_tone", "professional")
                    report = generate_full_gpt_report(user_profile, context_history, tone=tone)
                    st.success("âœ… å ±å‘Šç”¢å‡ºå®Œæˆï¼")
                    st.markdown(report)
                except Exception as e:
                    st.error(f"âŒ å ±å‘Šç”¢å‡ºå¤±æ•—ï¼š{e}")
