import os
import json
import openai
import streamlit as st
from typing import List, Dict
from src.managers.profile_manager import get_user_profile
from src.utils.gpt_tools import call_gpt

# åˆå§‹åŒ– OpenAI API key
openai.api_key = os.getenv("OPENAI_API_KEY")

# å–å¾—ä½¿ç”¨è€…è¨­å®šæª”
user_profile = get_user_profile()

# åˆå§‹åŒ–è¨˜æ†¶çµæ§‹
if "context_history" not in st.session_state:
    st.session_state["context_history"] = []
if "qa_threads" not in st.session_state:
    st.session_state["qa_threads"] = {}
if "guided_chat" not in st.session_state:
    st.session_state["guided_chat"] = []
if "guided_turns" not in st.session_state:
    st.session_state["guided_turns"] = 0


# --- æ¯é¡Œæ‘˜è¦ç´€éŒ„ï¼ˆfor é¡§å•ç”¨ï¼‰ ---
def add_context_entry(question_id: str, user_response, question_text: str):
    answer_text = ", ".join(user_response) if isinstance(user_response, list) else str(user_response)

    prompt = f"""è«‹ç”¨80-120ç¸½çµä»¥ä¸‹ ESG å•é¡Œèˆ‡å›ç­”çš„é‡é»ï¼Œç”¨æ–¼é¡§å•å›é¡§ä½¿ç”¨ï¼š

å•é¡Œï¼š{question_text}
å›ç­”ï¼š{answer_text}

æ‘˜è¦ï¼š"""

    try:
        completion = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å”åŠ©ä¼æ¥­è¨ºæ–· ESG ç‹€æ³çš„é¡§å•åŠ©ç†ï¼Œæ“…é•·å¿«é€Ÿæ‘˜è¦ä½¿ç”¨è€…å›è¦†ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=100
        )
        summary = completion["choices"][0]["message"]["content"].strip()

        # å…ˆç§»é™¤èˆŠçš„åŒé¡Œç´€éŒ„
        st.session_state["context_history"] = [
            item for item in st.session_state["context_history"]
            if item["id"] != question_id
        ]

        # åŠ å…¥æ–°æ‘˜è¦
        st.session_state["context_history"].append({
            "id": question_id,
            "answer": answer_text,
            "summary": summary
        })

        return summary

    except Exception as e:
        print(f"âš ï¸ GPT æ‘˜è¦å¤±æ•—ï¼š{e}")
        return "ï¼ˆæ‘˜è¦å¤±æ•—ï¼‰"


def get_all_summaries() -> List[str]:
    """å¾ `qa_threads` ä¸­ç²å–æ‰€æœ‰å•é¡Œçš„æ‘˜è¦ï¼ˆæœ€å¾Œä¸€è¼ªå›ç­”ï¼‰ã€‚"""
    return [
        f"Q{q_id}ï¼š{st.session_state.qa_threads[q_id][-1]['assistant']}"
        for q_id in st.session_state.qa_threads
    ]


# --- å°è©±ç´€éŒ„ç®¡ç† ---
def get_conversation(question_id: str) -> List[Dict[str, str]]:
    return st.session_state.qa_threads.get(question_id, [])

def add_turn(question_id: str, user_input: str, assistant_reply: str):
    if question_id not in st.session_state.qa_threads:
        st.session_state.qa_threads[question_id] = []
    st.session_state.qa_threads[question_id].append({
        "user": user_input,
        "assistant": assistant_reply
    })


# --- è‡ªå‹•ç”¢ç”Ÿå¾ŒçºŒå»ºè­°ï¼ˆé€²éšç‰ˆï¼‰ ---
def generate_following_action(current_q: dict, user_answer: str = "", user_profile: dict = None) -> str:
    question_text = current_q.get("text", "")
    topic = current_q.get("topic", "")
    learning_goal = current_q.get("learning_goal", "")
    user_profile_json = json.dumps(user_profile or {}, ensure_ascii=False, indent=2)

    prompt = f"""
ä½ æ˜¯ä¸€ä½ ESG é¡§å•ï¼Œè«‹æ ¹æ“šä½¿ç”¨è€…é‡å°ä¸‹åˆ— ESG å•é¡Œçš„å›ç­”å…§å®¹ï¼Œç”¢å‡ºã€Œä¸‹ä¸€æ­¥è¡Œå‹•å»ºè­°ã€ï¼š

1. å»ºè­°å…§å®¹éœ€å…·é«”å¯è¡Œï¼Œèˆ‡è©²é¡Œå­¸ç¿’ç›®æ¨™å’Œä½¿ç”¨è€…èƒŒæ™¯ç›¸é—œã€‚
2. è«‹æ¢åˆ—å‡º 3â€“5 é»è¡Œå‹•å»ºè­°ã€‚
3. æ¯å€‹å»ºè­°è«‹ç°¡çŸ­èªªæ˜ï¼Œä¸¦é™„ä¸Šå¯¦è¡Œå»ºè­°çš„ç†ç”±ã€‚

ã€ä½¿ç”¨è€…èƒŒæ™¯ã€‘ï¼š
{user_profile_json}

ã€æœ¬é¡Œå…§å®¹ã€‘ï¼š
{question_text}

ã€å­¸ç¿’ç›®æ¨™ã€‘ï¼š
{learning_goal}

ã€ä½¿ç”¨è€…å›è¦†ã€‘ï¼š
{user_answer or 'ï¼ˆå°šæœªå¡«å¯«ï¼‰'}

è«‹ç”¨ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼š
1. å»ºè­° A...
2. å»ºè­° B...
ğŸ‘‰ é¼“å‹µèªå¥
"""

    try:
        reply = call_gpt(prompt=prompt)
        return reply.strip()
    except Exception as e:
        return f"âš ï¸ ç„¡æ³•ç”¢ç”Ÿå»ºè­°ï¼š{e}"
