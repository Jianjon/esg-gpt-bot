import os
import json
import openai
import streamlit as st
from typing import List, Dict
from src.managers.profile_manager import get_user_profile
from src.utils.gpt_tools import call_gpt
from src.utils.topic_to_rag_map import get_rag_doc_for_question  # âœ… è‡ªå‹•é¸æ“‡å‘é‡åº«

# åˆå§‹åŒ– OpenAI API key
openai.api_key = os.getenv("OPENAI_API_KEY")

# å–å¾—ä½¿ç”¨è€…è¨­å®šæª”
user_profile = get_user_profile()

# åˆå§‹åŒ–è¨˜æ†¶çµæ§‹
if "context_history" not in st.session_state:
    st.session_state["context_history"] = []
if "qa_threads" not in st.session_state:
    st.session_state["qa_threads"] = {}
if "guided_chat" not in st.session_state:
    st.session_state["guided_chat"] = []
if "guided_turns" not in st.session_state:
    st.session_state["guided_turns"] = 0


# --- æ¯é¡Œæ‘˜è¦ç´€éŒ„ï¼ˆfor é¡§å•ç”¨ï¼‰ ---
def add_context_entry(question_id: str, user_response, question_text: str):
    answer_text = ", ".join(user_response) if isinstance(user_response, list) else str(user_response)

    prompt = f"""è«‹ç”¨80-120ç¸½çµä»¥ä¸‹ ESG å•é¡Œèˆ‡å›ç­”çš„é‡é»ï¼Œç”¨æ–¼é¡§å•å›é¡§ä½¿ç”¨ï¼š

å•é¡Œï¼š{question_text}
å›ç­”ï¼š{answer_text}

æ‘˜è¦ï¼š"""

    try:
        completion = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å”åŠ©ä¼æ¥­è¨ºæ–· ESG ç‹€æ³çš„é¡§å•åŠ©ç†ï¼Œæ“…é•·å¿«é€Ÿæ‘˜è¦ä½¿ç”¨è€…å›è¦†ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=100
        )
        summary = completion["choices"][0]["message"]["content"].strip()

        # å…ˆç§»é™¤èˆŠçš„åŒé¡Œç´€éŒ„
        st.session_state["context_history"] = [
            item for item in st.session_state["context_history"]
            if item["id"] != question_id
        ]

        # åŠ å…¥æ–°æ‘˜è¦
        st.session_state["context_history"].append({
            "id": question_id,
            "answer": answer_text,
            "summary": summary
        })

        return summary

    except Exception as e:
        print(f"âš ï¸ GPT æ‘˜è¦å¤±æ•—ï¼š{e}")
        return "ï¼ˆæ‘˜è¦å¤±æ•—ï¼‰"


def get_all_summaries() -> List[str]:
    """å¾ `qa_threads` ä¸­ç²å–æ‰€æœ‰å•é¡Œçš„æ‘˜è¦ï¼ˆæœ€å¾Œä¸€è¼ªå›ç­”ï¼‰ã€‚"""
    return [
        f"Q{q_id}ï¼š{st.session_state.qa_threads[q_id][-1]['assistant']}"
        for q_id in st.session_state.qa_threads
    ]


# --- å°è©±ç´€éŒ„ç®¡ç† ---
def get_conversation(question_id: str) -> List[Dict[str, str]]:
    return st.session_state.qa_threads.get(question_id, [])

def add_turn(question_id: str, user_input: str, assistant_reply: str):
    if question_id not in st.session_state.qa_threads:
        st.session_state.qa_threads[question_id] = []
    st.session_state.qa_threads[question_id].append({
        "user": user_input,
        "assistant": assistant_reply
    })


# --- è‡ªå‹•ç”¢ç”Ÿå¾ŒçºŒå»ºè­°ï¼ˆé€²éšç‰ˆï¼‰ ---
def generate_following_action(current_q: dict, user_answer: str = "", user_profile: dict = None) -> str:
    import os
    import json
    from src.utils.gpt_tools import call_gpt
    from src.utils.topic_to_rag_map import get_rag_doc_for_question

    question_text = current_q.get("text", "")
    topic = current_q.get("topic", "")
    learning_goal = current_q.get("learning_goal", "")
    user_profile_json = json.dumps(user_profile or {}, ensure_ascii=False, indent=2)

    # âœ… å˜—è©¦å–å¾— rag_docï¼Œä¸¦æª¢æŸ¥å‘é‡è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨
    try:
        rag_doc = get_rag_doc_for_question(current_q)
        rag_path = os.path.join("data", "vector_output_hf", rag_doc)
        if not os.path.exists(rag_path):
            print(f"âš ï¸ æ‰¾ä¸åˆ°å‘é‡è³‡æ–™å¤¾ï¼š{rag_path}ï¼Œç•¥é RAGã€‚")
            rag_doc = None
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•å–å¾—å‘é‡è³‡æ–™å¤¾ï¼ˆRAG ç•¥éï¼‰ï¼š{e}")
        rag_doc = None

    prompt = f"""
ä½ æ˜¯ä¸€ä½ ESG é¡§å•ï¼Œç†Ÿæ‚‰ä¸­å°ä¼æ¥­å¸¸è¦‹ç‡Ÿé‹æƒ…å¢ƒèˆ‡åˆè¦æŒ‘æˆ°ã€‚è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šï¼Œç”¢å‡ºã€Œ3 æ¢å…·é«”å¯åŸ·è¡Œçš„ä¸‹ä¸€æ­¥è¡Œå‹•å»ºè­°ã€ã€‚å­—æ•¸æ§åˆ¶åœ¨ 160 å­—å…§ã€‚

ã€ç›®æ¨™ã€‘
- å»ºè­°å¿…é ˆèƒ½çœŸæ­£åŸ·è¡Œï¼Œä¸å¾—ç©ºæ³›
- èšç„¦å¯¦éš›è¡Œå‹•ï¼šå¯ä»¥å»ºç«‹ä»€éº¼åˆ¶åº¦ã€æ‰¾èª°åˆä½œã€åšå“ªç¨®æº–å‚™
- æ¯æ¢å»ºè­°ç¨ç«‹æˆå¥ï¼Œç°¡æ½”æœ‰åŠ›ï¼Œä¸è£œå……èªªæ˜ã€ä¸åŒ…è£èªæ°£

ã€èªæ°£é¢¨æ ¼ã€‘
- è«‹æ¨¡ä»¿ GPT èˆ‡ä½¿ç”¨è€…çš„å°è©±èªæ°£
- **èªæ°£æº«å’Œä½†å‹™å¯¦**ï¼Œå¯ä»¥åŠ å…¥ã€Œé€™æ¨£èƒ½å¹«åŠ©â‹¯ã€ã€Œé€™æ¨£åšå¯ä»¥ç¢ºä¿â‹¯ã€ç­‰è§£é‡‹
- å¯æ­é… **ç²—é«”é—œéµè©** æˆ– emoji åšè¦–è¦ºå¼·èª¿

ã€æ’ç‰ˆè¦æ±‚ã€‘
- è«‹å°‡å»ºè­°åˆ†ç‚º 3 æ®µï¼Œæ¯ä¸€æ®µä»¥ emojiï¼ˆâœ… ğŸ“Œ ğŸ”§ ç­‰ï¼‰é–‹é ­
- æ¯æ®µè½**ä¸è¶…éå…©è¡Œ**ï¼Œä¸­é–“å¯é©åº¦æ›è¡Œï¼Œä¿æŒ GPT å°è©±é¢¨æ ¼çš„ç¯€å¥
- æ¯æ®µéƒ½æ‡‰åŒ…å«ä¸€å€‹ã€Œæ˜ç¢ºè¡Œå‹•ã€+ã€Œé€™æ¨£åšçš„åŸå› ã€
- ä¿æŒç•™ç™½èˆ‡å¯è®€æ€§ï¼Œé¿å…å¯†å¯†éº»éº»,æ’ç‰ˆè¦å¥½çœ‹,ä¸èƒ½å¤ªå¯†é›†
- æ¢åˆ—å¼æ™‚è©¦å¾—è¦æ–·è¡Œï¼Œä¸èƒ½å¤ªé•·


ã€æ ¼å¼æç¤ºã€‘
- **ç²—é«”** ç”¨æ–¼å¼·èª¿é‡é»
- ã€Œã€ç”¨æ–¼æŠ€è¡“è¡“èªã€å°ˆæœ‰è©
- ï¼ˆï¼‰ç”¨æ–¼è¼”åŠ©èªªæ˜æˆ–åˆ¤æ–·æ¢ä»¶
- è‹¥éœ€æ¢åˆ—å¼èªªæ˜ï¼Œè«‹ä½¿ç”¨ã€Œ-ã€é–‹é ­çš„æ¸…å–®æ ¼å¼
- è‹¥éœ€å¼•ç”¨æˆ–åƒè€ƒè³‡æ–™ï¼Œè«‹ä½¿ç”¨ã€Œ>ã€é–‹é ­çš„å¼•ç”¨æ ¼å¼
- å›æ‡‰æ–‡å­—è«‹æ§åˆ¶åœ¨ ChatGPT é¢¨æ ¼çš„å…§æ–‡ç¯„åœï¼ˆç´„ 16px é¡¯ç¤ºå¤§å°ï¼‰

ã€ä½¿ç”¨è€…èƒŒæ™¯ã€‘
{user_profile_json}

ã€é¡Œç›®å…§å®¹ã€‘
{question_text}

ã€å­¸ç¿’ç›®æ¨™ã€‘
{learning_goal}

ã€ä½¿ç”¨è€…å›è¦†ã€‘
{user_answer or 'ï¼ˆå°šæœªå¡«å¯«ï¼‰'}

è«‹ç”¢å‡ºå°ˆæ¥­å»ºè­°ï¼ˆ3 æ¢ï¼‰ï¼Œèªæ°£ä¸­æ€§ã€ä¸ç©ºè«‡ã€ä¸å®¢å¥—ã€‚
    """

    try:
        from src.utils.gpt_tools import call_gpt
        reply = call_gpt(prompt=prompt, rag_doc=rag_doc)
        return reply.strip()
    except Exception as e:
        print(f"âš ï¸ GPT å‘¼å«å¤±æ•—ï¼š{e}")
        return "âš ï¸ ç„¡æ³•ç”¢ç”Ÿå»ºè­°ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
