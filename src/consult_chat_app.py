import streamlit as st
from src.loaders.question_loader import load_questions
from src.sessions.answer_session import AnswerSession
from src.sessions import context_tracker
from src.generators.report_generator import generate_basic_report
from src.utils.vector_guard import VectorStore
from src.managers.guided_rag import GuidedRAG
from src.managers.gpt_rewrite import rewrite_question_to_conversational
from src.utils.topic_progress import get_topic_progress
from session_logger import save_to_json
import openai
import os
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

from src.utils.gpt_tools import call_gpt


# è¼‰å…¥è‡ªè¨‚æ¨£å¼
def local_css(file_path):
    with open(file_path, encoding="utf-8") as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

local_css("assets/custom_style.css")

# --- Sidebarï¼šChatGPT é¢¨æ ¼çš„ ESG Service Path ---
st.sidebar.markdown("## ESG Service Path")
st.sidebar.markdown("---")

# é¡¯ç¤ºä½¿ç”¨è€…åç¨±
user_name = st.session_state.get("user_name", "Guest")
st.sidebar.markdown(f"ä½¿ç”¨è€…ï¼š**{user_name}**")

# åˆå§‹åŒ–å•å·ç‹€æ…‹
if 'welcome_submitted' not in st.session_state or not st.session_state['welcome_submitted']:
    st.warning("è«‹å…ˆå®Œæˆç”¢æ¥­é¸æ“‡èˆ‡å…¬å¸åŸºæœ¬è³‡æ–™å¡«å¯«ã€‚")
    st.stop()

industry = st.session_state['industry']
stage = st.session_state.get('stage', 'basic')

# åˆå§‹åŒ– AnswerSession
user_id = f"{st.session_state.get('company_name', 'unknown')}_{st.session_state.get('user_name', 'user')}"
questions = load_questions(industry, stage)

if 'session' not in st.session_state:
    st.session_state.session = AnswerSession(user_id=user_id, question_set=questions)

session = st.session_state.session

# é¡¯ç¤ºä¸»é¡Œé€²åº¦åœ–
answered_ids = {r["question_id"] for r in session.responses}
fig = get_topic_progress(session.question_set, answered_ids)
st.sidebar.pyplot(fig)

# é¡¯ç¤ºç›®å‰é¡Œç›®
current_q = session.get_current_question()
if current_q:
    # ä½¿ç”¨ GPT é‡å¯«é¡Œç›®ç‚ºå°è©±é¢¨æ ¼
    gpt_text = rewrite_question_to_conversational(
        current_q["text"],
        question_type=current_q.get("type", "single"),
        learning_goal=current_q.get("learning_goal", ""),
        use_gpt=True
    )

    # é¡¯ç¤ºé¡Œç›®èˆ‡ GPT é‡å¯«çš„å°è©±é¢¨æ ¼é¡Œç›®
    st.markdown(
        f"<div class='fixed-question'>{current_q['text']}</div>",
        unsafe_allow_html=True
    )
    st.markdown(f"<div class='ai-message'>{gpt_text}</div>", unsafe_allow_html=True)

    # === GPT å°è©±å¼å•ç­”å€å¡Š ===
    st.divider()
    st.markdown("### ğŸ¤– å•é¡Œæ©Ÿå™¨äººï¼ˆé‡å°æœ¬é¡Œé€²è¡Œå»¶ä¼¸æå•ï¼‰")

    # åˆå§‹åŒ– context_tracker çš„ chat è¨˜æ†¶
    if "qa_threads" not in st.session_state:
        st.session_state.qa_threads = {}

    from sessions.context_tracker import get_conversation, add_turn
    from src.utils.gpt_tools import call_gpt  # ä½ åŸæœ¬è‡ªå®šç¾©çš„ GPT å‘¼å«å‡½å¼

    chat_id = current_q["id"]
    history = get_conversation(chat_id)

    # é¡¯ç¤ºå°è©±ç´€éŒ„ï¼ˆä¸ŠåŠéƒ¨ï¼‰
    for msg in history:
        with st.chat_message("user"):
            st.markdown(msg["user"])
        with st.chat_message("assistant"):
            st.markdown(msg["gpt"])

    # åŠ ä¸Š follow-up æç¤ºï¼ˆå»ºè­°æå•æ–¹å‘ï¼‰
    st.markdown("##### ğŸ’¡ æå•å»ºè­°")
    st.info(current_q.get("follow_up", "ç›®å‰å°šç„¡æç¤ºï¼Œæ‚¨å¯è‡ªç”±ç™¼å•"))

# è¨­å®šæ¯é¡Œæœ€å¤šå°è©±è¼ªæ•¸
MAX_TURNS = 5
if len(history) >= MAX_TURNS:
    st.warning("æ‚¨å·²é‡å°æœ¬é¡Œé€²è¡Œäº†å¤šè¼ªæå•ï¼Œå»ºè­°å‰å¾€ä¸‹ä¸€é¡Œä»¥æŒçºŒå­¸ç¿’ ğŸ˜Š")
    if st.button("ğŸ‘‰ å‰å¾€ä¸‹ä¸€é¡Œ"):
        session.next()
        st.rerun()
    st.stop()



# ä¸‹åŠéƒ¨è¼¸å…¥å€
if prompt := st.chat_input("é‡å°æœ¬é¡Œé‚„æœ‰ä»€éº¼å•é¡Œï¼Ÿå¯è©¢å• ESG å°ˆå®¶ AI"):
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("AI å›è¦†ä¸­..."):
            try:
                # å‘¼å«æ”¹è‰¯ç‰ˆ call_gptï¼Œå‚³å…¥å®Œæ•´åƒæ•¸
                gpt_reply = call_gpt(
                    prompt=prompt,
                    question_text=current_q["text"],
                    learning_goal=current_q.get("learning_goal", ""),
                    chat_history=get_conversation(chat_id),
                    industry=st.session_state.get("industry", "")
                )
                st.markdown(gpt_reply)
                add_turn(chat_id, prompt, gpt_reply)

            except Exception as e:
                st.error(f"âš ï¸ AI å›è¦†å¤±æ•—ï¼š{str(e)}")

