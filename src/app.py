import streamlit as st
from sessions.answer_session import AnswerSession
from sessions.context_tracker import add_context_entry, get_all_summaries
from managers.baseline_manager import BaselineManager
from managers.report_manager import ReportManager
from managers.feedback_manager import FeedbackManager
from loaders.question_loader import load_questions
from session_logger import save_to_json, load_from_json, save_to_sqlite
from dotenv import load_dotenv
import matplotlib.pyplot as plt
import os
import json
from pathlib import Path
import logging
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
import faiss
import fitz  # PyMuPDF
from typing import List, Dict, Tuple
import re
from vector_builder import PDFProcessor, MetadataHandler

load_dotenv()

st.set_page_config(page_title="ESG å•å·è¨ºæ–·", layout="wide")
st.title("ğŸ“‹ ESG æ™ºèƒ½å•å·è¨ºæ–· | æ·¨é›¶å°å¹«æ‰‹")

# --- åŸºæœ¬é©—è­‰ ---
if "user_name" not in st.session_state or "industry" not in st.session_state:
    st.warning("è«‹å…ˆå¾ welcome.py é€²å…¥ä¸¦å¡«å¯«åŸºæœ¬è³‡è¨Šã€‚")
    st.stop()

if "stage" not in st.session_state:
    st.session_state.stage = "basic"

# --- å•é¡Œèˆ‡ä½¿ç”¨è€… ID åˆå§‹åŒ– ---
user_id = f"{st.session_state.get('company_name', 'unknown')}_{st.session_state.get('user_name', 'user')}"
question_set = load_questions(st.session_state.industry, st.session_state.stage)

# --- Session åˆå§‹åŒ–æˆ–è¼‰å…¥ ---
if "session" not in st.session_state:
    session = load_from_json(user_id, question_set)
    if session:
        if st.button("ğŸ”„ ç¹¼çºŒä¸Šæ¬¡ç­”é¡Œé€²åº¦"):
            st.session_state.session = session
            st.rerun()
        else:
            st.warning("åµæ¸¬åˆ°æ‚¨æœ‰æœªå®Œæˆçš„å•å·è¨˜éŒ„ï¼Œæ‚¨å¯ä»¥é¸æ“‡ç¹¼çºŒæˆ–é‡æ–°é–‹å§‹ã€‚")
            st.stop()
    else:
        st.session_state.session = AnswerSession(user_id=user_id, question_set=question_set)

session = st.session_state.session
current_q = session.get_current_question()

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("ğŸ‘¤ ä½¿ç”¨è€…è³‡è¨Š")
    st.markdown(f"**å§“åï¼š** {st.session_state.user_name}")
    st.markdown(f"**Emailï¼š** {st.session_state.get('user_email', '-')}")
    st.markdown(f"**å…¬å¸ï¼š** {st.session_state.company_name}")
    st.markdown(f"**ç”¢æ¥­é¡åˆ¥ï¼š** {st.session_state.industry}")
    st.markdown(f"**éšæ®µï¼š** {'åˆéš' if st.session_state.stage == 'basic' else 'é€²éš'}")
    st.markdown("---")
    st.markdown("### ğŸ“Š ä¸»é¡Œé€²åº¦æ¦‚è¦½")
    topic_progress = session.get_topic_progress()
    topics = list(topic_progress.keys())
    answered = [v["answered"] for v in topic_progress.values()]
    totals = [v["total"] for v in topic_progress.values()]
    fig, ax = plt.subplots()
    ax.barh(topics, totals, color="#eee", label="ç¸½é¡Œæ•¸")
    ax.barh(topics, answered, color="#4CAF50", label="å·²å®Œæˆ")
    ax.invert_yaxis()
    ax.legend()
    st.pyplot(fig)

# --- å•å·æµç¨‹ ---
progress = session.get_progress()
st.progress(progress["percent"] / 100, text=f"ç›®å‰é€²åº¦ï¼š{progress['answered']} / {progress['total']} é¡Œ")

if current_q:
    st.markdown(f"### â“ å•é¡Œ {session.current_index + 1}")
    st.markdown(current_q["text"])

    if current_q["type"] == "single":
        response = st.radio("è«‹é¸æ“‡ä¸€å€‹é¸é …ï¼š", current_q["options"])
    else:
        response = st.multiselect("å¯è¤‡é¸ï¼š", current_q["options"])

    if st.button("âœ… æäº¤å›ç­”"):
        result = session.submit_response(response)
        add_context_entry(current_q["id"], response, current_q["text"])
        save_to_json(session)
        if "error" in result:
            st.error(result["error"])
        else:
            st.rerun()
else:
    st.success("ğŸ‰ æ‚¨å·²å®Œæˆæœ¬éšæ®µå•å·ï¼")
    baseline = BaselineManager("data/baselines/company_abc.json").get_baseline()
    summary = session.get_summary(company_baseline=baseline)
    summary["user_name"] = st.session_state.get("user_name")
    summary["company_name"] = st.session_state.get("company_name")
    report = ReportManager(summary)
    feedback_mgr = FeedbackManager(summary.get("comparison", []))

    st.markdown("## ğŸ“„ è¨ºæ–·æ‘˜è¦å ±å‘Š")
    st.markdown(f"```\n{report.generate_text_report()}\n```")

    st.markdown("## ğŸ’¡ é¡Œç›®å»ºè­°èˆ‡æ”¹å–„æ–¹å‘")
    for fb in feedback_mgr.generate_feedback():
        st.markdown(f"- **{fb['question_id']} å»ºè­°ï¼š** {fb['feedback']}")

    st.markdown("## ğŸ“Œ ç¸½é«”å»ºè­°")
    st.markdown(feedback_mgr.generate_overall_feedback())

    save_to_json(session)
    save_to_sqlite(session)

    # é€²å…¥é€²éšè¨ºæ–·
    if st.session_state.stage == "basic":
        st.divider()
        st.subheader("ğŸš€ æ‚¨å·²å®Œæˆåˆéšè¨ºæ–·ï¼Œæ˜¯å¦é€²å…¥é€²éšéšæ®µï¼Ÿ")
        if st.button("ğŸ‘‰ é€²å…¥é€²éšå•å·"):
            st.session_state.stage = "advanced"
            new_qset = load_questions(st.session_state.industry, "advanced")
            st.session_state.session = AnswerSession(user_id=user_id, question_set=new_qset)
            st.rerun()

# è¨­ç½® OpenAI API
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    dimensions=1536
)

# è¨­ç½®æ–‡æœ¬åˆ†å‰²å™¨
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=400,
    chunk_overlap=50,
    separators=["\n\n", "\n", "ã€‚", ".", "!", "?", "ï¼", "ï¼Ÿ"],
    keep_separator=True
)

# ä¸»è¦è™•ç†æµç¨‹
def process_pdf(pdf_path: Path):
    # 1. è®€å– PDF
    # 2. åˆ†æ®µ
    # 3. ç”Ÿæˆ metadata
    # 4. å»ºç«‹å‘é‡
    # 5. å„²å­˜åˆ° FAISS
    pass

class ChunkMetadata:
    def __init__(self, pdf_path: Path, page: int, section: int):
        self.chunk_id = f"{pdf_path.stem}-p{page}-s{section}"
        self.source = pdf_path.name
        self.path = str(pdf_path.parent.relative_to(base_dir))
        self.main_topic = self._extract_topic(pdf_path)
        self.industry = self._extract_industry(pdf_path)
        self.region = self._extract_region(pdf_path)
        self.page = page
        self.title = ""  # å¾ PDF æå–
        self.language = self._detect_language()

class VectorStore:
    def __init__(self):
        self.dimension = 1536
        self.index = faiss.IndexFlatIP(self.dimension)  # cosine similarity
        self.metadata = []
    
    def add_vectors(self, vectors, metadata_list):
        self.index.add(vectors)
        self.metadata.extend(metadata_list)
    
    def save(self, output_dir: Path):
        faiss.write_index(self.index, str(output_dir / 'faiss_index.index'))
        with open(output_dir / 'chunk_metadata.json', 'w') as f:
            json.dump(self.metadata, f, indent=2)

def main():
    # è¨­ç½®æ—¥èªŒ
    logging.basicConfig(
        filename='data/vector_output/build_log.txt',
        level=logging.INFO
    )
    
    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    output_dir = Path('data/vector_output')
    output_dir.mkdir(exist_ok=True)
    
    # è™•ç†æ¯å€‹è³‡æ–™å¤¾
    base_dir = Path('data/db_pdf_data')
    for folder in ['cases', 'international', 'taiwan']:
        process_folder(base_dir / folder)

    # åœ¨main.pyä¸­ä½¿ç”¨
    pdf_processor = PDFProcessor()
    metadata_handler = MetadataHandler()

    def process_single_pdf(pdf_path: Path):
        # è™•ç†PDFä¸¦ç²å–chunks
        chunks_with_metadata = pdf_processor.process_pdf(pdf_path)
        
        # æ“´å……metadata
        enriched_chunks = []
        for chunk, metadata in chunks_with_metadata:
            enriched_metadata = metadata_handler.enrich_metadata(metadata, chunk)
            enriched_chunks.append((chunk, enriched_metadata))
        
        return enriched_chunks
