import streamlit as st

if "user_name" not in st.session_state:
    st.switch_page("1_welcome")
    st.stop()

if "intro_survey_submitted" not in st.session_state:
    st.switch_page("2_intro_survey")
    st.stop()

st.set_page_config(page_title="ESG å•å·è©•æ–·", layout="centered")

# _init_app ç¸½é«”è™•ç†ç’°å¢ƒè¨­å®šèˆ‡ sys.path
import _init_app

# å¥—ç”¨è‡ªå®šç¾© CSS æ¨£å¼
with open("assets/custom_style.css", encoding="utf-8") as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

# é¡¯ç¤º Topbar
st.markdown("""
    <style>
        div[data-testid="stAppViewContainer"] > .main {{
            padding-top: 64px;
        }}
    </style>
    <div class="topbar">
        <div class="logo">ğŸŒ± ESG Service Path</div>
        <div class="user-info">{}</div>
    </div>
""".format(st.session_state.get("user_name", "æœªç™»å…¥").upper()), unsafe_allow_html=True)

from collections import defaultdict
from pathlib import Path
import pandas as pd
import os
import json
import matplotlib.pyplot as plt
import faiss
import fitz
import re
from typing import List, Dict, Tuple

from sessions.answer_session import AnswerSession
from sessions.context_tracker import get_conversation, add_context_entry, add_turn
# from sessions.context_tracker import get_all_summaries
from managers.baseline_manager import BaselineManager
from managers.report_manager import ReportManager
from managers.feedback_manager import FeedbackManager
from session_logger import save_to_json, load_from_json, save_to_sqlite
from vector_builder.pdf_processor import PDFProcessor
from vector_builder.metadata_handler import MetadataHandler
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from src.components.suggest_box import render_suggested_questions

MODULE_MAP = {
    "C": "ESG æ•™å­¸å°å…¥ï¼ˆæ•™å­¸å‰å°ï¼‰",
    "B": "é‚Šç•Œè¨­å®šèˆ‡çµ„ç¹”è³‡è¨Š",
    "S": "æ’æ”¾æºè¾¨è­˜èˆ‡ç¢ºèª",
    "D": "æ•¸æ“šæ”¶é›†æ–¹å¼èˆ‡èƒ½åŠ›",
    "M": "å…§éƒ¨ç®¡ç†èˆ‡SOPç¾æ³",
    "R": "å ±å‘Šéœ€æ±‚èˆ‡å¾ŒçºŒè¡Œå‹•"
}

INDUSTRY_FILE_MAP = {
    "é¤é£²æ¥­": "Restaurant.csv",
    "æ—…å®¿æ¥­": "Hotel.csv",
    "é›¶å”®æ¥­": "Retail.csv",
    "å°å‹è£½é€ æ¥­": "SmallManufacturing.csv",
    "ç‰©æµæ¥­": "Logistics.csv",
    "è¾¦å…¬å®¤æœå‹™æ¥­": "Offices.csv"
}

STAGE_MAP = {
    "basic": "beginner",
    "advanced": "intermediate"
}

TOPIC_ORDER = [
    "ESG æ•™å­¸å°å…¥ï¼ˆæ•™å­¸å‰å°ï¼‰",
    "é‚Šç•Œè¨­å®šèˆ‡çµ„ç¹”è³‡è¨Š",
    "æ’æ”¾æºè¾¨è­˜èˆ‡ç¢ºèª",
    "æ•¸æ“šæ”¶é›†æ–¹å¼èˆ‡èƒ½åŠ›",
    "å…§éƒ¨ç®¡ç†èˆ‡SOPç¾æ³",
    "å ±å‘Šéœ€æ±‚èˆ‡å¾ŒçºŒè¡Œå‹•"
]

def load_questions(industry: str, stage: str = "basic", skip_common: bool = False) -> list:
    filename = INDUSTRY_FILE_MAP.get(industry)
    if not filename:
        raise ValueError(f"æ‰¾ä¸åˆ°ç”¢æ¥­å°æ‡‰çš„é¡Œåº«ï¼š{industry}")
    path = os.path.join("data", filename)
    if not os.path.exists(path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°é¡Œåº«æª”æ¡ˆï¼š{path}")

    df = pd.read_csv(path)
    required_cols = ["question_id", "question_text", "difficulty_level", "option_type", "answer_tags"]
    for col in required_cols:
        if col not in df.columns:
            raise ValueError(f"é¡Œåº«ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{col}")

    if stage not in STAGE_MAP:
        raise ValueError(f"è¼¸å…¥å€¼éŒ¯èª¤ï¼šstage æ‡‰ç‚º basic æˆ– advancedï¼Œä½†æ”¶åˆ°ï¼š{stage}")
    mapped_stage = STAGE_MAP[stage]
    df = df[df["difficulty_level"].isin([mapped_stage] if stage == "basic" else ["beginner", "intermediate"])]

    questions = []
    for _, row in df.iterrows():
        qid = row["question_id"]
        topic = row.get("topic_category", "").strip() or MODULE_MAP.get(qid[0], "æœªåˆ†é¡")
        options, option_notes = [], {}
        for opt in ["A", "B", "C", "D", "E"]:
            val = row.get(f"option_{opt}")
            if pd.notna(val):
                options.append(val)
                option_notes[val] = row.get(f"option_{opt}_note", "")

        questions.append({
            "id": qid,
            "industry": row.get("industry_type", industry),
            "text": row.get("question_text", "æœªå¡«é¡Œç›®å…§å®¹"),
            "options": options,
            "option_notes": option_notes,
            "type": row.get("option_type", "single"),
            "topic": topic,
            "difficulty": row.get("difficulty_level", mapped_stage),
            "report_section": row.get("report_section", ""),
            "tags": row.get("answer_tags", "").split("|") if isinstance(row.get("answer_tags"), str) else [],
            "allow_custom_answer": row.get("allow_custom_answer", False),
            "allow_skip": row.get("allow_skip", False),
            "note": row.get("free_answer_note", ""),
            "question_note": row.get("question_note", ""),
            "learning_objective": row.get("learning_objective", ""),
            "report_topic": row.get("report_topic", ""),
            "learning_goal": row.get("learning_goal", ""),
            "follow_up": row.get("follow_up", "")
        })

    if skip_common:
        questions = [q for q in questions if not (q["id"].startswith("C0"))]

    def question_sort_key(q):
        topic_index = TOPIC_ORDER.index(q["topic"]) if q["topic"] in TOPIC_ORDER else 999
        qid = q["id"]
        num_part = int(qid[1:]) if qid[1:].isdigit() else 999
        return (topic_index, num_part)

    return sorted(questions, key=question_sort_key)

# ===== åˆå§‹åŒ–è¨­å®š =====
if "stage" not in st.session_state:
    st.session_state.stage = "basic"
if "jump_to" not in st.session_state:
    st.session_state["jump_to"] = None

user_id = f"{st.session_state.get('company_name', 'unknown')}_{st.session_state.get('user_name', 'user')}"
current_stage = st.session_state.stage

questions = load_questions(
    industry=st.session_state.industry,
    stage=current_stage,
    skip_common=True
)

if "session" not in st.session_state:
    session_file = Path("data/sessions") / f"{st.session_state.company_name}_{st.session_state.user_name}.json"
    if session_file.exists():
        if st.session_state.get("reset_data"):
            session_file.unlink()
            st.toast("âœ… å·²æ¸…é™¤åŸæœ‰ç´€éŒ„ï¼Œå•å·å°‡å¾é ­é–‹å§‹ã€‚")
            st.session_state.session = AnswerSession(user_id=user_id, question_set=questions)
        else:
            session = load_from_json(user_id, questions)
            if session:
                if st.button("ğŸ”„ ç¹¼çºŒä¸Šæ¬¡ç­”é¡Œé€²åº¦"):
                    st.session_state.session = session
                    st.rerun()
                else:
                    st.warning("åµæ¸¬åˆ°æ‚¨æœ‰æœªå®Œæˆçš„å•å·ç´€éŒ„ï¼Œæ‚¨å¯ä»¥é¸æ“‡ç¹¼çºŒæˆ–é‡æ–°é–‹å§‹ã€‚")
                    st.stop()
    else:
        st.session_state.session = AnswerSession(user_id=user_id, question_set=questions)

session = st.session_state.session
current_q = session.get_current_question()

# ===== å•Ÿç”¨ jump_to è·³é¡Œ =====
if st.session_state.get("jump_to"):
    qid = st.session_state["jump_to"]
    index = next((i for i, item in enumerate(session.question_set) if item["id"] == qid), None)
    if index is not None:
        session.jump_to(index)
        st.session_state["jump_to"] = None
        st.rerun()

# å›ºå®šä¸»é«”å®¹å™¨
st.markdown('<div class="main-content-container">', unsafe_allow_html=True)

# ä¸»é«”å…§å®¹ï¼šå•é¡Œä¸»é«”ã€èªªæ˜èˆ‡é¸é …
if current_q:
    st.markdown(f"### ğŸ‘£ ç›®å‰é€²åº¦ï¼šç¬¬ {session.current_index + 1} é¡Œ / å…± {len(session.question_set)} é¡Œ")
    st.markdown(f"#### ğŸ¯ å­¸ç¿’ä¸»é¡Œï¼š<br>{current_q.get('learning_goal', '')}", unsafe_allow_html=True)
    st.markdown(f"**é¡Œç›®èªªæ˜ï¼š** {current_q.get('question_note', '')}")
    st.markdown("---")

    # é¡¯ç¤ºé¸é …å€‘
    options = current_q["options"]
    option_notes = current_q.get("option_notes", {})
    labeled_options = [f"{opt}ï¼š{option_notes.get(opt, '')}" for opt in options]

    selected = []

    if current_q["type"] == "single":
        selected_option = st.radio("å¯é¸æ“‡ï¼š", labeled_options)
        if selected_option:
            selected = [selected_option.split("ï¼š")[0]]
    else:
        st.markdown("å¯è¤‡é¸ï¼š")
        for opt in labeled_options:
            opt_key = opt.split("ï¼š")[0]
            if st.checkbox(opt, key=opt_key):
                selected.append(opt_key)
    # âœ… è‹¥å…è¨±ä½¿ç”¨è€…è‡ªè¨‚ç­”æ¡ˆ
    custom_input = ""
    if current_q.get("allow_custom_answer", False):
        custom_input = st.text_input("âœï¸ æˆ–å¡«å¯«è‡ªè¨‚ç­”æ¡ˆï¼š", key="custom_input")

    # ğŸ§  æ±ºå®šæœ€å¾Œé€å‡ºçš„ç­”æ¡ˆ
    if custom_input:
        selected = [custom_input] if current_q["type"] == "single" else selected + [custom_input]
      

    st.markdown("---")
    # å°èˆªæŒ‰éˆ•å€å¡Š
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("ğŸ‘ˆ ä¸Šä¸€é¡Œ", key="btn_prev", use_container_width=True):
            session.go_back()
            st.rerun()
    with col2:
        if st.button("ğŸ‘‰ ä¸‹ä¸€é¡Œ", key="btn_next", use_container_width=True):
            # æ ¹æ“šé¡Œå‹è™•ç†ç­”æ¡ˆæ ¼å¼
            if current_q["type"] == "single":
                answer_payload = selected[0] if selected else ""
            else:
                answer_payload = selected

            # æäº¤ç­”æ¡ˆ
            result = session.submit_response(answer_payload)
            add_context_entry(current_q["id"], selected, current_q["text"])
            save_to_json(session)
            if "error" in result:
                st.error(result["error"])
            else:
                st.rerun()

    # === GPT å°è©±å¼å•ç­”å€å¡Š ===
    st.divider()
    st.markdown("#### ğŸ¤– æ·¨é›¶å°å¹«æ‰‹ï¼ˆæ¸¬è©¦éšæ®µä»¥äº”é¡Œç‚ºé™ï¼‰")

    # åˆå§‹åŒ–å°è©±è¨˜æ†¶
    if "qa_threads" not in st.session_state:
        st.session_state.qa_threads = {}

    chat_id = current_q["id"]
    from sessions.context_tracker import get_conversation, add_turn
    from src.utils.gpt_tools import call_gpt

    # é¡¯ç¤ºæ­·å²å°è©±
    for msg in get_conversation(chat_id):
        if "user" in msg:
            with st.chat_message("user"):
                st.markdown(msg["user"])
        if "gpt" in msg:
            with st.chat_message("assistant"):
                st.markdown(msg["gpt"])



    # å®šç¾©é»æŒ‰æŒ‰éˆ•å¾Œè‡ªå‹•é€å‡ºçš„è™•ç†æµç¨‹
    def auto_submit_prompt(selected_prompt):
        from src.utils.gpt_tools import call_gpt
        from sessions.context_tracker import add_turn, get_conversation

        with st.chat_message("user"):
            st.markdown(selected_prompt)
        with st.chat_message("assistant"):
            with st.spinner("AI å›è¦†ä¸­..."):
                context_text = f"{current_q['text']}\n{current_q.get('learning_goal', '')}"
                reply = call_gpt(
                prompt=selected_prompt,
                question_text=current_q["text"],
                learning_goal=current_q.get("learning_goal", ""),
                chat_history=get_conversation(current_q["id"]),
                industry=st.session_state.get("industry", "")
            )

                st.markdown(reply)
                add_turn(current_q["id"], selected_prompt, reply)

    # ğŸ’¡ è‡ªå‹•å¾é¡Œç›®å¸¶å…¥å»ºè­°æå•ï¼ˆæ”¯æ´è‡ªç„¶èªå¥æ ¼å¼ï¼‰
    suggested_prompts_raw = current_q.get("follow_up", "")
    suggested_prompts = [
        s.strip() + "ï¼Ÿ"
        for s in suggested_prompts_raw.split("ï¼Ÿ")
        if s.strip()
]

    # ğŸ”µ åœ¨ chat_input ä¸Šæ–¹æ’å…¥å»ºè­°å•é¡ŒæŒ‰éˆ•å€
    render_suggested_questions(suggested_prompts, auto_submit_prompt)



    # ä¸‹æ–¹è¼¸å…¥æ¡†
    if prompt := st.chat_input("é‡å°æœ¬é¡Œé‚„æœ‰ä»€éº¼å•é¡Œï¼Ÿå¯è©¢å• ESG é¡§å• AI"):
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("AI å›è¦†ä¸­..."):
                try:
                    reply = call_gpt(prompt)  
                    st.markdown(reply)
                    add_turn(chat_id, prompt, reply)
                except Exception as e:
                    st.error(f"âš ï¸ AI å›è¦†å¤±æ•—ï¼š{str(e)}")

 
else:  # ç¢ºä¿é€™è£¡çš„ else èˆ‡ä¸Šæ–¹ if å°é½Š
    st.success("ğŸ‰ æ‚¨å·²å®Œæˆæœ¬éšæ®µå•å·ï¼")
    baseline = BaselineManager("data/baselines/company_abc.json").get_baseline()
    summary = session.get_summary(company_baseline=baseline)
    summary["user_name"] = st.session_state.get("user_name")
    summary["company_name"] = st.session_state.get("company_name")
    report = ReportManager(summary)
    feedback_mgr = FeedbackManager(summary.get("comparison", []))

    st.markdown("## ğŸ“„ è¨ºæ–·æ‘˜è¦å ±å‘Š")
    st.markdown(f"""
```
{report.generate_text_report()}
```
""")

    st.markdown("## ğŸ’¡ é¡Œç›®å»ºè­°èˆ‡æ”¹å–„æ–¹å‘")
    for fb in feedback_mgr.generate_feedback():
        st.markdown(f"- **{fb['question_id']} å»ºè­°ï¼š** {fb['feedback']}")

    st.markdown("## ğŸ“Œ ç¸½é«”å»ºè­°")
    st.markdown(feedback_mgr.generate_overall_feedback())

    save_to_json(session)
    save_to_sqlite(session)

    if st.session_state.stage == "basic":
        st.divider()
        st.subheader("ğŸš€ æ‚¨å·²å®Œæˆåˆéšè¨ºæ–·ï¼Œæ˜¯å¦é€²å…¥é€²éšå•å·ï¼Ÿ")
        if st.button("ğŸ‘‰ é€²å…¥é€²éšå•å·"):
            st.session_state.stage = "advanced"
            new_qset = load_questions(st.session_state.industry, "advanced", skip_common=True)
            st.session_state.session = AnswerSession(user_id=user_id, question_set=new_qset)
            st.rerun()

# å‘é‡è™•ç†ï¼ˆæš«ä¿ç•™ï¼‰
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")


text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=400,
    chunk_overlap=50,
    separators=["\n\n", "\n", "ã€‚", ".", "!", "?", "ï¼", "ï¼Ÿ"],
    keep_separator=True
)

base_dir = Path("data/db_pdf_data")

class ChunkMetadata:
    def __init__(self, pdf_path: Path, page: int, section: int, base_dir: Path):
        self.chunk_id = f"{pdf_path.stem}-p{page}-s{section}"
        self.source = pdf_path.name
        self.path = str(pdf_path.parent.relative_to(base_dir))
        self.main_topic = ""
        self.industry = ""
        self.region = ""
        self.page = page
        self.title = ""
        self.language = ""

class VectorStore:
    def __init__(self):
        self.dimension = 1536
        self.index = faiss.IndexFlatIP(self.dimension)
        self.metadata = []

    def add_vectors(self, vectors, metadata_list):
        self.index.add(vectors)
        self.metadata.extend(metadata_list)

    def save(self, output_dir: Path):
        faiss.write_index(self.index, str(output_dir / 'faiss_index.index'))
        with open(output_dir / 'chunk_metadata.json', 'w') as f:
            json.dump(self.metadata, f, indent=2)

# ğŸ“„ app.py

import streamlit as st
from src.loaders.question_loader import load_questions  # æ­£ç¢ºå¼•ç”¨æ­¤å‡½å¼

def show_learning_page():
    # è®€å– session_state ä¸­çš„éšæ®µèˆ‡ç”¢æ¥­è³‡æ–™
    stage = st.session_state.get("stage", "basic")  # é»˜èªç‚ºåˆéš
    industry = st.session_state.get("industry", "é¤é£²æ¥­")  # é»˜èªç‚ºé¤é£²æ¥­

    # æ ¹æ“šéšæ®µè¼‰å…¥é¡Œç›®
    questions = load_questions(industry=industry, stage=stage)

    st.markdown("## ğŸ¯ é–‹å§‹æ‚¨çš„ ESG å­¸ç¿’ä¹‹æ—…")
    st.markdown("""
    æ­¡è¿ä¾†åˆ°å­¸ç¿’é é¢ï¼é€™è£¡æ˜¯ç‚ºæ‚¨é‡èº«è¨­è¨ˆçš„å­¸ç¿’è·¯å¾‘ï¼Œè®“æˆ‘å€‘é–‹å§‹æ¢ç´¢å¦‚ä½•é€²è¡Œç¢³ç›¤æŸ¥ã€äº†è§£ ESG çš„æ ¸å¿ƒæ¦‚å¿µï¼Œä¸¦å¹«åŠ©æ‚¨èˆ‡ä¼æ¥­åˆä½œæ¸›ç¢³ã€‚
    """)

    # é¡¯ç¤ºå­¸ç¿’å…§å®¹
    st.markdown("### å­¸ç¿’æ¨¡çµ„ 1: ç¢³ç›¤æŸ¥æ¦‚è¿°")
    st.markdown("åœ¨é€™å€‹æ¨¡çµ„ä¸­ï¼Œæ‚¨å°‡å­¸åˆ°å¦‚ä½•é€²è¡Œç¢³ç›¤æŸ¥ã€ä»€éº¼æ˜¯ç¢³è¶³è·¡...")

    # é¡¯ç¤ºé¡Œç›®ï¼Œä¾ç…§ `stage` é¡¯ç¤ºå°æ‡‰é¡Œç›®
    st.markdown("### é€™æ˜¯æ‚¨çš„å•å·é¡Œç›®ï¼š")
    for question in questions:
        st.markdown(f"**{question['text']}**")  # é¡¯ç¤ºå•é¡Œ
        for option in question["options"]:  # é¡¯ç¤ºé¸é …
            st.markdown(f"- {option}")

import streamlit as st

st.set_page_config(page_title="ESG å•å·ä¸»æµç¨‹", layout="centered")

# é€²å…¥å•å·ä¸»ç•«é¢ï¼ˆæ­¤è™•é–‹å§‹æ‰é€²è¡Œå­¸ç¿’èˆ‡å•ç­”ï¼‰
st.markdown(f"### ğŸ¯ æ­¡è¿ {st.session_state.user_name}ï¼Œé–‹å§‹ ESG å•ç­”è¨ºæ–·")
# ...è¼‰å…¥é¡Œåº«èˆ‡ä¸»æµç¨‹é‚è¼¯
