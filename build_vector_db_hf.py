# build_vector_db_hf.py
"""
ä½¿ç”¨ HuggingFace æ¨¡å‹å»ºç«‹å‘é‡è³‡æ–™åº«ï¼ˆä¸æœƒç”¢ç”Ÿ OpenAI è²»ç”¨ï¼‰
è™•ç† PDF ä¸¦å»ºç«‹ FAISS å‘é‡èˆ‡ metadataï¼Œä¸¦è¨˜éŒ„å·²è™•ç†æª”æ¡ˆ
"""

from pathlib import Path
import json
import logging
from tqdm import tqdm
from vector_builder import PDFProcessor, MetadataHandler
from vector_builder.embeddings import get_embedding
from vector_builder.vector_store import VectorStore


def load_processed_record(record_path: Path) -> dict:
    if record_path.exists():
        with open(record_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_processed_record(record_path: Path, record: dict):
    with open(record_path, 'w', encoding='utf-8') as f:
        json.dump(record, f, ensure_ascii=False, indent=2)

def main():
    pdf_processor = PDFProcessor()
    metadata_handler = MetadataHandler()
    vector_store = VectorStore()

    base_dir = Path("data/db_pdf_data")
    output_dir = Path("data/vector_output_hf")

    log_file = output_dir / "build_log.txt"
    record_file = output_dir / "vector_build_record.json"
    processed_record = load_processed_record(record_file)

    output_dir.mkdir(parents=True, exist_ok=True)

    logging.basicConfig(
        filename=log_file,
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s"
    )

    print("é–‹å§‹å‘é‡è³‡æ–™åº«å»ºç½®...")
    logging.info("=== å•Ÿå‹•å»ºç½®ç¨‹åº ===")

    folder_list = ["cases", "international", "taiwan"]
    pdf_paths = [p for folder in folder_list for p in (base_dir / folder).rglob("*.pdf")]

    for pdf_path in tqdm(pdf_paths, desc="ğŸ“ ç¸½é«”é€²åº¦"):
        file_id = str(pdf_path.resolve())
        if file_id in processed_record:
            print(f"ğŸŸ¡ ç•¥éå·²è™•ç†ï¼š{pdf_path.name}")
            continue

        print(f"\nğŸ“„ è™•ç†æª”æ¡ˆï¼š{pdf_path.name}")
        logging.info(f"è™•ç†ï¼š{pdf_path.name}")

        try:
            chunks = pdf_processor.process_pdf(pdf_path)
        except Exception as e:
            logging.error(f"PDF è™•ç†å¤±æ•— ({pdf_path.name})ï¼š{e}")
            continue

        pdf_name_cleaned = pdf_path.stem.strip()
        pdf_output_dir = output_dir / pdf_name_cleaned
        pdf_output_dir.mkdir(parents=True, exist_ok=True)

        vector_store = VectorStore()  # âœ… æ¯ä¸€ä»½ PDF ä½¿ç”¨æ–° index

        for chunk_text, raw_meta in tqdm(chunks, desc="ğŸ”¹ åˆ†æ®µèˆ‡å·¾å…¥", leave=False):
            enriched = metadata_handler.enrich_metadata(raw_meta, chunk_text)
            enriched["text"] = chunk_text

            try:
                vector = get_embedding(chunk_text)
                vector_store.add_vectors([vector], [enriched])
            except Exception as e:
                logging.error(f"å‘é‡å·¾å…¥å¤±æ•— ({pdf_path.name})ï¼š{e}")

        try:
            vector_store.save(pdf_output_dir)
            processed_record[file_id] = {"filename": pdf_path.name}
            save_processed_record(record_file, processed_record)
        except Exception as e:
            logging.error(f"å„²å­˜å‘é‡å¤±æ•— ({pdf_path.name})ï¼š{e}")

    print("âœ… å»ºç½®å®Œæˆï¼")
    logging.info("=== å»ºç½®å®Œæˆ ===")

if __name__ == "__main__":
    main()